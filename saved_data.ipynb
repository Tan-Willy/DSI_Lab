{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 4, Lab 2: Predicting Chronic Kidney Disease in Patients\n",
    "> Author: Matt Brems\n",
    "\n",
    "We can sketch out the data science process as follows:\n",
    "1. Define the problem.\n",
    "2. Obtain the data.\n",
    "3. Explore the data.\n",
    "4. Model the data.\n",
    "5. Evaluate the model.\n",
    "6. Answer the problem.\n",
    "\n",
    "In this lab, we're going to focus on steps exploring data, building models and evaluating the models we build.\n",
    "\n",
    "There are three links you may find important:\n",
    "- [A set of chronic kidney disease (CKD) data and other biological factors](./chronic_kidney_disease_full.csv).\n",
    "- [The CKD data dictionary](./chronic_kidney_disease_header.txt).\n",
    "- [An article comparing the use of k-nearest neighbors and support vector machines on predicting CKD](./chronic_kidney_disease.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define the problem.\n",
    "\n",
    "Suppose you're working for Mayo Clinic, widely recognized to be the top hospital in the United States. In your work, you've overheard nurses and doctors discuss test results, then arrive at a conclusion as to whether or not someone has developed a particular disease or condition. For example, you might overhear something like:\n",
    "\n",
    "> **Nurse**: Male 57 year-old patient presents with severe chest pain. FDP _(short for fibrin degradation product)_ was elevated at 13. We did an echo _(echocardiogram)_ and it was inconclusive.\n",
    "\n",
    "> **Doctor**: What was his interarm BP? _(blood pressure)_\n",
    "\n",
    "> **Nurse**: Systolic was 140 on the right; 110 on the left.\n",
    "\n",
    "> **Doctor**: Dammit, it's an aortic dissection! Get to the OR _(operating room)_ now!\n",
    "\n",
    "> _(intense music playing)_\n",
    "\n",
    "In this fictitious but [Shonda Rhimes-esque](https://en.wikipedia.org/wiki/Shonda_Rhimes#Grey's_Anatomy,_Private_Practice,_Scandal_and_other_projects_with_ABC) scenario, you might imagine the doctor going through a series of steps like a [flowchart](https://en.wikipedia.org/wiki/Flowchart), or a series of if-this-then-that steps to diagnose a patient. The first steps made the doctor ask what the interarm blood pressure was. Because interarm blood pressure took on the values it took on, the doctor diagnosed the patient with an aortic dissection.\n",
    "\n",
    "Your goal, as a research biostatistical data scientist at the nation's top hospital, is to develop a medical test that can improve upon our current diagnosis system for [chronic kidney disease (CKD)](https://www.mayoclinic.org/diseases-conditions/chronic-kidney-disease/symptoms-causes/syc-20354521).\n",
    "\n",
    "**Real-world problem**: Develop a medical diagnosis test that is better than our current diagnosis system for CKD.\n",
    "\n",
    "**Data science problem**: Develop a medical diagnosis test that reduces both the number of false positives and the number of false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Obtain the data.\n",
    "\n",
    "### 1. Read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wbcc</th>\n",
       "      <th>rbcc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>423.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age    bp     sg   al   su     rbc        pc         pcc          ba  \\\n",
       "0  48.0  80.0  1.020  1.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "1   7.0  50.0  1.020  4.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "2  62.0  80.0  1.010  2.0  3.0  normal    normal  notpresent  notpresent   \n",
       "3  48.0  70.0  1.005  4.0  0.0  normal  abnormal     present  notpresent   \n",
       "4  51.0  80.0  1.010  2.0  0.0  normal    normal  notpresent  notpresent   \n",
       "\n",
       "     bgr  ...   pcv    wbcc  rbcc  htn   dm  cad  appet   pe  ane class  \n",
       "0  121.0  ...  44.0  7800.0   5.2  yes  yes   no   good   no   no   ckd  \n",
       "1    NaN  ...  38.0  6000.0   NaN   no   no   no   good   no   no   ckd  \n",
       "2  423.0  ...  31.0  7500.0   NaN   no  yes   no   poor   no  yes   ckd  \n",
       "3  117.0  ...  32.0  6700.0   3.9  yes   no   no   poor  yes  yes   ckd  \n",
       "4  106.0  ...  35.0  7300.0   4.6   no   no   no   good   no   no   ckd  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv('../4_02-lab-classification_model_evaluation/chronic_kidney_disease_full.csv')\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Check out the data dictionary. What are a few features or relationships you might be interested in checking out?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Age, Blood Pressure and Hypertension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Explore the data.\n",
    "\n",
    "### 3. How much of the data is missing from each column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age        9\n",
       "bp        12\n",
       "sg        47\n",
       "al        46\n",
       "su        49\n",
       "rbc      152\n",
       "pc        65\n",
       "pcc        4\n",
       "ba         4\n",
       "bgr       44\n",
       "bu        19\n",
       "sc        17\n",
       "sod       87\n",
       "pot       88\n",
       "hemo      52\n",
       "pcv       71\n",
       "wbcc     106\n",
       "rbcc     131\n",
       "htn        2\n",
       "dm         2\n",
       "cad        2\n",
       "appet      1\n",
       "pe         1\n",
       "ane        1\n",
       "class      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Suppose that I dropped every row that contained at least one missing value. (In the context of analysis with missing data, we call this a \"complete case analysis,\" because we keep only the complete cases!) How many rows would remain in our dataframe? What are at least two downsides to doing this?\n",
    "\n",
    "> There's a good visual on slide 15 of [this deck](https://liberalarts.utexas.edu/prc/_files/cs/Missing-Data.pdf) that shows what a complete case analysis looks like if you're interested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wbcc</th>\n",
       "      <th>rbcc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>53.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>70.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>12100.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>63.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>380.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>68.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>present</td>\n",
       "      <td>157.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>61.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>173.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9200.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>55.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>140.0</td>\n",
       "      <td>...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>notckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>42.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>75.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>notckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>12.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>6600.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>notckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>114.0</td>\n",
       "      <td>...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>notckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>58.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>131.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>6800.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>notckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age    bp     sg   al   su       rbc        pc         pcc          ba  \\\n",
       "3    48.0  70.0  1.005  4.0  0.0    normal  abnormal     present  notpresent   \n",
       "9    53.0  90.0  1.020  2.0  0.0  abnormal  abnormal     present  notpresent   \n",
       "11   63.0  70.0  1.010  3.0  0.0  abnormal  abnormal     present  notpresent   \n",
       "14   68.0  80.0  1.010  3.0  2.0    normal  abnormal     present     present   \n",
       "20   61.0  80.0  1.015  2.0  0.0  abnormal  abnormal  notpresent  notpresent   \n",
       "..    ...   ...    ...  ...  ...       ...       ...         ...         ...   \n",
       "395  55.0  80.0  1.020  0.0  0.0    normal    normal  notpresent  notpresent   \n",
       "396  42.0  70.0  1.025  0.0  0.0    normal    normal  notpresent  notpresent   \n",
       "397  12.0  80.0  1.020  0.0  0.0    normal    normal  notpresent  notpresent   \n",
       "398  17.0  60.0  1.025  0.0  0.0    normal    normal  notpresent  notpresent   \n",
       "399  58.0  80.0  1.025  0.0  0.0    normal    normal  notpresent  notpresent   \n",
       "\n",
       "       bgr  ...   pcv     wbcc  rbcc  htn   dm  cad  appet   pe  ane   class  \n",
       "3    117.0  ...  32.0   6700.0   3.9  yes   no   no   poor  yes  yes     ckd  \n",
       "9     70.0  ...  29.0  12100.0   3.7  yes  yes   no   poor   no  yes     ckd  \n",
       "11   380.0  ...  32.0   4500.0   3.8  yes  yes   no   poor  yes   no     ckd  \n",
       "14   157.0  ...  16.0  11000.0   2.6  yes  yes  yes   poor  yes   no     ckd  \n",
       "20   173.0  ...  24.0   9200.0   3.2  yes  yes  yes   poor  yes  yes     ckd  \n",
       "..     ...  ...   ...      ...   ...  ...  ...  ...    ...  ...  ...     ...  \n",
       "395  140.0  ...  47.0   6700.0   4.9   no   no   no   good   no   no  notckd  \n",
       "396   75.0  ...  54.0   7800.0   6.2   no   no   no   good   no   no  notckd  \n",
       "397  100.0  ...  49.0   6600.0   5.4   no   no   no   good   no   no  notckd  \n",
       "398  114.0  ...  51.0   7200.0   5.9   no   no   no   good   no   no  notckd  \n",
       "399  131.0  ...  53.0   6800.0   6.1   no   no   no   good   no   no  notckd  \n",
       "\n",
       "[158 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: 158 rows will remain in our dataframe from the initial 400 rows. The 2 downsides of doing this is that if too many rows are dropped, it reduces the statistical power. Alot of datas are not usable and the estimates might be biased. If too much data are dropped, we will need the hospital to collect more data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Thinking critically about how our data were gathered, it's likely that these records were gathered by doctors and nurses. Brainstorm three potential areas (in addition to the missing data we've already discussed) where this data might be inaccurate or imprecise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The patients may not go through all the tests to get all the data as the cost of checkup can be quite costly. They will only go the for tests that are required for their individual condition. Some of the doctors and nurses could be new professionals and might read some data wrongly and wrote wrongly. Some patients may not be cooperative and therefore some data could not be collected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4: Model the data.\n",
    "\n",
    "### 6. Suppose that I want to construct a model where no person who has CKD will ever be told that they do not have CKD. What (very simple, no machine learning needed) model can I create that will never tell a person with CKD that they do not have CKD?\n",
    "\n",
    "> Hint: Don't think about `statsmodels` or `scikit-learn` here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: For every person with or without CKD, we will tell them that they have CKD. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. In problem 6, what common classification metric did we optimize for? Did we minimize false positives or negatives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: We optimized True Positive. We minimized false positive because there isn't anyone who have CKD but we predicted wrongly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Thinking ethically, what is at least one disadvantage to the model you described in problem 6?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The disadvantage is to predict those who do not have CKD as having CKD and this will bring down the confidence in our predictive model. People who was told that they have CKD will have a shock of their life and angry after knowing they actually do not have CKD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Suppose that I want to construct a model where a person who does not have CKD will ever be told that they do have CKD. What (very simple, no machine learning needed) model can I create that will accomplish this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: For every person with or without CKD, we will tell them that they do not have CKD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. In problem 9, what common classification metric did we optimize for? Did we minimize false positives or negatives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: We optimized True Negative. We minimized false negative because there isn't anyone who do not have CKD but we predicted wrongly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Thinking ethically, what is at least one disadvantage to the model you described in problem 9?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The disadvantage is to predict those who have CKD as not having CKD and this will bring down the confidence in our predictive model. People who was told that they do not have CKD but in actual fact they do have CKD, will cost those people their lives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Construct a logistic regression model in `sklearn` predicting class from the other variables. You may scale, select/drop, and engineer features as you wish - build a good model! Make sure, however, that you include at least one categorical/dummy feature and at least one quantitative feature.\n",
    "\n",
    "> Hint: Remember to do a train/test split!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age        9\n",
       "bp        12\n",
       "sg        47\n",
       "al        46\n",
       "su        49\n",
       "rbc      152\n",
       "pc        65\n",
       "pcc        4\n",
       "ba         4\n",
       "bgr       44\n",
       "bu        19\n",
       "sc        17\n",
       "sod       87\n",
       "pot       88\n",
       "hemo      52\n",
       "pcv       71\n",
       "wbcc     106\n",
       "rbcc     131\n",
       "htn        2\n",
       "dm         2\n",
       "cad        2\n",
       "appet      1\n",
       "pe         1\n",
       "ane        1\n",
       "class      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 25 columns):\n",
      "age      391 non-null float64\n",
      "bp       388 non-null float64\n",
      "sg       353 non-null float64\n",
      "al       354 non-null float64\n",
      "su       351 non-null float64\n",
      "rbc      248 non-null object\n",
      "pc       335 non-null object\n",
      "pcc      396 non-null object\n",
      "ba       396 non-null object\n",
      "bgr      356 non-null float64\n",
      "bu       381 non-null float64\n",
      "sc       383 non-null float64\n",
      "sod      313 non-null float64\n",
      "pot      312 non-null float64\n",
      "hemo     348 non-null float64\n",
      "pcv      329 non-null float64\n",
      "wbcc     294 non-null float64\n",
      "rbcc     269 non-null float64\n",
      "htn      398 non-null object\n",
      "dm       398 non-null object\n",
      "cad      398 non-null object\n",
      "appet    399 non-null object\n",
      "pe       399 non-null object\n",
      "ane      399 non-null object\n",
      "class    400 non-null object\n",
      "dtypes: float64(14), object(11)\n",
      "memory usage: 78.2+ KB\n"
     ]
    }
   ],
   "source": [
    "results.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['sg'] = results.sg.astype(str)\n",
    "results['al'] = results.al.astype(str)\n",
    "results['su'] = results.su.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = results._get_numeric_data().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = list(num_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = list(set(results) - set(num_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'bp', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv', 'wbcc', 'rbcc']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rbc',\n",
       " 'pc',\n",
       " 'htn',\n",
       " 'al',\n",
       " 'appet',\n",
       " 'class',\n",
       " 'dm',\n",
       " 'pe',\n",
       " 'pcc',\n",
       " 'ba',\n",
       " 'ane',\n",
       " 'sg',\n",
       " 'cad',\n",
       " 'su']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age        9\n",
       "bp        12\n",
       "sg         0\n",
       "al         0\n",
       "su         0\n",
       "rbc      152\n",
       "pc        65\n",
       "pcc        4\n",
       "ba         4\n",
       "bgr       44\n",
       "bu        19\n",
       "sc        17\n",
       "sod       87\n",
       "pot       88\n",
       "hemo      52\n",
       "pcv       71\n",
       "wbcc     106\n",
       "rbcc     131\n",
       "htn        2\n",
       "dm         2\n",
       "cad        2\n",
       "appet      1\n",
       "pe         1\n",
       "ane        1\n",
       "class      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>bgr</th>\n",
       "      <th>bu</th>\n",
       "      <th>sc</th>\n",
       "      <th>sod</th>\n",
       "      <th>pot</th>\n",
       "      <th>hemo</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wbcc</th>\n",
       "      <th>rbcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.4</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.6</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>111.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>11.2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.6</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>55.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>15.7</td>\n",
       "      <td>47.0</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>42.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>141.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>16.5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>12.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>137.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>15.8</td>\n",
       "      <td>49.0</td>\n",
       "      <td>6600.0</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>14.2</td>\n",
       "      <td>51.0</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>58.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>141.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>15.8</td>\n",
       "      <td>53.0</td>\n",
       "      <td>6800.0</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age    bp    bgr    bu   sc    sod  pot  hemo   pcv    wbcc  rbcc\n",
       "0    48.0  80.0  121.0  36.0  1.2    NaN  NaN  15.4  44.0  7800.0   5.2\n",
       "1     7.0  50.0    NaN  18.0  0.8    NaN  NaN  11.3  38.0  6000.0   NaN\n",
       "2    62.0  80.0  423.0  53.0  1.8    NaN  NaN   9.6  31.0  7500.0   NaN\n",
       "3    48.0  70.0  117.0  56.0  3.8  111.0  2.5  11.2  32.0  6700.0   3.9\n",
       "4    51.0  80.0  106.0  26.0  1.4    NaN  NaN  11.6  35.0  7300.0   4.6\n",
       "..    ...   ...    ...   ...  ...    ...  ...   ...   ...     ...   ...\n",
       "395  55.0  80.0  140.0  49.0  0.5  150.0  4.9  15.7  47.0  6700.0   4.9\n",
       "396  42.0  70.0   75.0  31.0  1.2  141.0  3.5  16.5  54.0  7800.0   6.2\n",
       "397  12.0  80.0  100.0  26.0  0.6  137.0  4.4  15.8  49.0  6600.0   5.4\n",
       "398  17.0  60.0  114.0  50.0  1.0  135.0  4.9  14.2  51.0  7200.0   5.9\n",
       "399  58.0  80.0  131.0  18.0  1.1  141.0  3.5  15.8  53.0  6800.0   6.1\n",
       "\n",
       "[400 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[num_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in results[num_col]:\n",
    "    results[i] = results[i].fillna(results[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.drop(['rbc','pc'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age      0\n",
       "bp       0\n",
       "sg       0\n",
       "al       0\n",
       "su       0\n",
       "pcc      4\n",
       "ba       4\n",
       "bgr      0\n",
       "bu       0\n",
       "sc       0\n",
       "sod      0\n",
       "pot      0\n",
       "hemo     0\n",
       "pcv      0\n",
       "wbcc     0\n",
       "rbcc     0\n",
       "htn      2\n",
       "dm       2\n",
       "cad      2\n",
       "appet    1\n",
       "pe       1\n",
       "ane      1\n",
       "class    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = [col for col in cat_col if col!=('pc')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col  = [col for col in cat_col if col!=('rbc')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in results[cat_col]:\n",
    "    results[i] = pd.get_dummies(results[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.heatmap(results.corr(),cmap='coolwarm');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = abs(results.corr()['class']).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class    1.000000\n",
       "hemo     0.726616\n",
       "al       0.720927\n",
       "pcv      0.685938\n",
       "htn      0.584641\n",
       "rbcc     0.581948\n",
       "dm       0.553272\n",
       "su       0.412618\n",
       "bgr      0.394751\n",
       "appet    0.388351\n",
       "pe       0.370318\n",
       "bu       0.367252\n",
       "sod      0.341292\n",
       "ane      0.321034\n",
       "sc       0.289354\n",
       "bp       0.279804\n",
       "pcc      0.261619\n",
       "cad      0.232750\n",
       "age      0.227435\n",
       "wbcc     0.208341\n",
       "ba       0.184171\n",
       "sg       0.101848\n",
       "pot      0.078005\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "logr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = results[['hemo','al','pcv','htn','rbcc','dm','su','bgr','appet','pe','bu','sod','ane']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = results['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ss = ss.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_ss = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Willy\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>class</td>      <th>  R-squared:         </th> <td>   0.705</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.695</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   69.58</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 28 Nov 2019</td> <th>  Prob (F-statistic):</th> <td>7.71e-92</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:12:44</td>     <th>  Log-Likelihood:    </th> <td> -30.406</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   393</td>      <th>  AIC:               </th> <td>   88.81</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   379</td>      <th>  BIC:               </th> <td>   144.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    2.3996</td> <td>    0.241</td> <td>    9.943</td> <td> 0.000</td> <td>    1.925</td> <td>    2.874</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hemo</th>  <td>   -0.0550</td> <td>    0.011</td> <td>   -5.113</td> <td> 0.000</td> <td>   -0.076</td> <td>   -0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>al</th>    <td>   -0.3515</td> <td>    0.039</td> <td>   -9.016</td> <td> 0.000</td> <td>   -0.428</td> <td>   -0.275</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pcv</th>   <td>   -0.0079</td> <td>    0.003</td> <td>   -2.289</td> <td> 0.023</td> <td>   -0.015</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>htn</th>   <td>   -0.0370</td> <td>    0.040</td> <td>   -0.916</td> <td> 0.360</td> <td>   -0.116</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rbcc</th>  <td>   -0.0408</td> <td>    0.024</td> <td>   -1.698</td> <td> 0.090</td> <td>   -0.088</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dm</th>    <td>   -0.1120</td> <td>    0.042</td> <td>   -2.697</td> <td> 0.007</td> <td>   -0.194</td> <td>   -0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>su</th>    <td>    0.0259</td> <td>    0.040</td> <td>    0.643</td> <td> 0.520</td> <td>   -0.053</td> <td>    0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bgr</th>   <td>    0.0006</td> <td>    0.000</td> <td>    2.748</td> <td> 0.006</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>appet</th> <td>   -0.0481</td> <td>    0.039</td> <td>   -1.244</td> <td> 0.214</td> <td>   -0.124</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pe</th>    <td>   -0.0143</td> <td>    0.040</td> <td>   -0.355</td> <td> 0.723</td> <td>   -0.094</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bu</th>    <td>   -0.0011</td> <td>    0.000</td> <td>   -3.333</td> <td> 0.001</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sod</th>   <td>   -0.0028</td> <td>    0.002</td> <td>   -1.750</td> <td> 0.081</td> <td>   -0.006</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ane</th>   <td>    0.0929</td> <td>    0.047</td> <td>    1.985</td> <td> 0.048</td> <td>    0.001</td> <td>    0.185</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>29.633</td> <th>  Durbin-Watson:     </th> <td>   1.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  34.941</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.730</td> <th>  Prob(JB):          </th> <td>2.59e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.999</td> <th>  Cond. No.          </th> <td>3.99e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.99e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  class   R-squared:                       0.705\n",
       "Model:                            OLS   Adj. R-squared:                  0.695\n",
       "Method:                 Least Squares   F-statistic:                     69.58\n",
       "Date:                Thu, 28 Nov 2019   Prob (F-statistic):           7.71e-92\n",
       "Time:                        14:12:44   Log-Likelihood:                -30.406\n",
       "No. Observations:                 393   AIC:                             88.81\n",
       "Df Residuals:                     379   BIC:                             144.4\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          2.3996      0.241      9.943      0.000       1.925       2.874\n",
       "hemo          -0.0550      0.011     -5.113      0.000      -0.076      -0.034\n",
       "al            -0.3515      0.039     -9.016      0.000      -0.428      -0.275\n",
       "pcv           -0.0079      0.003     -2.289      0.023      -0.015      -0.001\n",
       "htn           -0.0370      0.040     -0.916      0.360      -0.116       0.042\n",
       "rbcc          -0.0408      0.024     -1.698      0.090      -0.088       0.006\n",
       "dm            -0.1120      0.042     -2.697      0.007      -0.194      -0.030\n",
       "su             0.0259      0.040      0.643      0.520      -0.053       0.105\n",
       "bgr            0.0006      0.000      2.748      0.006       0.000       0.001\n",
       "appet         -0.0481      0.039     -1.244      0.214      -0.124       0.028\n",
       "pe            -0.0143      0.040     -0.355      0.723      -0.094       0.065\n",
       "bu            -0.0011      0.000     -3.333      0.001      -0.002      -0.000\n",
       "sod           -0.0028      0.002     -1.750      0.081      -0.006       0.000\n",
       "ane            0.0929      0.047      1.985      0.048       0.001       0.185\n",
       "==============================================================================\n",
       "Omnibus:                       29.633   Durbin-Watson:                   1.305\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               34.941\n",
       "Skew:                           0.730   Prob(JB):                     2.59e-08\n",
       "Kurtosis:                       2.999   Cond. No.                     3.99e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.99e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y,X)\n",
    "ols = model.fit()\n",
    "ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = results[['hemo','al','pcv','dm','bgr','bu']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_ss = ss.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test_ss = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>class</td>      <th>  R-squared:         </th> <td>   0.693</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   145.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 28 Nov 2019</td> <th>  Prob (F-statistic):</th> <td>1.07e-95</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:12:44</td>     <th>  Log-Likelihood:    </th> <td> -38.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   393</td>      <th>  AIC:               </th> <td>   90.36</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   386</td>      <th>  BIC:               </th> <td>   118.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    1.9852</td> <td>    0.106</td> <td>   18.674</td> <td> 0.000</td> <td>    1.776</td> <td>    2.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hemo</th>  <td>   -0.0542</td> <td>    0.010</td> <td>   -5.235</td> <td> 0.000</td> <td>   -0.075</td> <td>   -0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>al</th>    <td>   -0.3672</td> <td>    0.037</td> <td>   -9.998</td> <td> 0.000</td> <td>   -0.439</td> <td>   -0.295</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pcv</th>   <td>   -0.0107</td> <td>    0.003</td> <td>   -3.275</td> <td> 0.001</td> <td>   -0.017</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dm</th>    <td>   -0.1457</td> <td>    0.037</td> <td>   -3.981</td> <td> 0.000</td> <td>   -0.218</td> <td>   -0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bgr</th>   <td>    0.0005</td> <td>    0.000</td> <td>    2.594</td> <td> 0.010</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bu</th>    <td>   -0.0011</td> <td>    0.000</td> <td>   -3.350</td> <td> 0.001</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>28.398</td> <th>  Durbin-Watson:     </th> <td>   1.317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  33.294</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.712</td> <th>  Prob(JB):          </th> <td>5.89e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.945</td> <th>  Cond. No.          </th> <td>1.41e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.41e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  class   R-squared:                       0.693\n",
       "Model:                            OLS   Adj. R-squared:                  0.688\n",
       "Method:                 Least Squares   F-statistic:                     145.1\n",
       "Date:                Thu, 28 Nov 2019   Prob (F-statistic):           1.07e-95\n",
       "Time:                        14:12:44   Log-Likelihood:                -38.178\n",
       "No. Observations:                 393   AIC:                             90.36\n",
       "Df Residuals:                     386   BIC:                             118.2\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          1.9852      0.106     18.674      0.000       1.776       2.194\n",
       "hemo          -0.0542      0.010     -5.235      0.000      -0.075      -0.034\n",
       "al            -0.3672      0.037     -9.998      0.000      -0.439      -0.295\n",
       "pcv           -0.0107      0.003     -3.275      0.001      -0.017      -0.004\n",
       "dm            -0.1457      0.037     -3.981      0.000      -0.218      -0.074\n",
       "bgr            0.0005      0.000      2.594      0.010       0.000       0.001\n",
       "bu            -0.0011      0.000     -3.350      0.001      -0.002      -0.000\n",
       "==============================================================================\n",
       "Omnibus:                       28.398   Durbin-Watson:                   1.317\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               33.294\n",
       "Skew:                           0.712   Prob(JB):                     5.89e-08\n",
       "Kurtosis:                       2.945   Cond. No.                     1.41e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.41e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y,X)\n",
    "ols = model.fit()\n",
    "ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Willy\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#logr.fit(X_train_ss,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = logr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9394904458598726"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8987341772151899"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.62917747, 0.10495906, 0.93173992, 0.53750987, 1.06069546,\n",
       "        1.03626958]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(logr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 5: Evaluate the model.\n",
    "\n",
    "### 13. Based on your logistic regression model constructed in problem 12, interpret the coefficient of one of your quantitative features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Answer: The coefficient of one of my quantitative feature,'bgr', is 1.06069546"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Based on your logistic regression model constructed in problem 12, interpret the coefficient of one of your categorical/dummy features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Answer: The coefficient of one of my categorical feature,'dm', is 0.53750987"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Despite being a relatively simple model, logistic regression is very widely used in the real world. Why do you think that's the case? Name at least two advantages to using logistic regression as a modeling technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: In the real world scenario, business owner/stakeholder always want to know if a project will be either positive or negative. Therefore logistic regression can help to give that outcome for stakeholder to make a decision. The advantages are that logistic regression are very informative and easy to interpret compared to other classification. Logistic regression can also handle nonlinear effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Does it make sense to generate a confusion matrix on our training data or our test data? Why? Generate it on the proper data.\n",
    "\n",
    "> Hint: Once you've generated your predicted $y$ values and you have your observed $y$ values, then it will be easy to [generate a confusion matrix using sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22,  0],\n",
       "       [ 8, 49]], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. In this hospital case, we want to predict CKD. Do we want to optimize for sensitivity, specificity, or something else? Why? (If you don't think there's one clear answer, that's okay! There rarely is. Be sure to defend your conclusion!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: We want to optimize sensitivity because we have to correctly predict those patient who have CKD as having CKD so that we can reduce the chance of a patient having CKD being told of not having CKD. Another metric to optimize is accuracy, although predicting those patient having CKD as having CKD, we also don't want to tell patient that they have CKD when they do not have CKD. Not only that we want our True positive to be high, we don't want to increase our True negative as well, therefore we need to have high accuracy and sensitivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18 (BONUS). Write a function that will create an ROC curve for you, then plot the ROC curve.\n",
    "\n",
    "Here's a strategy you might consider:\n",
    "1. In order to even begin, you'll need some fit model. Use your logistic regression model from problem 12.\n",
    "2. We want to look at all values of your \"threshold\" - that is, anything where .predict() gives you above your threshold falls in the \"positive class,\" and anything that is below your threshold falls in the \"negative class.\" Start the threshold at 0.\n",
    "3. At this value of your threshold, calculate the sensitivity and specificity. Store these values.\n",
    "4. Increment your threshold by some \"step.\" Maybe set your step to be 0.01, or even smaller.\n",
    "5. At this value of your threshold, calculate the sensitivity and specificity. Store these values.\n",
    "6. Repeat steps 3 and 4 until you get to the threshold of 1.\n",
    "7. Plot the values of sensitivity and 1 - specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. Suppose you're speaking with the biostatistics lead at Mayo Clinic, who asks you \"Why are unbalanced classes generally a problem? Are they a problem in this particular CKD analysis?\" How would you respond?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: If classes are unbalanced, the data collected may be biased towards one side. It will be ideal to have data that have balanced classes in order to have a more accurate prediction. The data for this analysis is still acceptable as the balance of the classes is about 40% against 60%, the biased level is not that strong in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. Suppose you're speaking with a doctor at Mayo Clinic who, despite being very smart, doesn't know much about data science or statistics. How would you explain why unbalanced classes are generally a problem to this doctor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: If there are 5 CKD patient and 5 non-CKD patient for our test. We can draw a fairer conclusion on a general trend based on the data collected such as age, blood pressure, diabetes, etc. If there are 2 CKD patient and 8 non-CKD patient for our test. The data collected from the 2 CKD patient may not accurately represent the general trend for CKD, therefore the prediction may be inaccurate as the model will predict more patient as non-CKD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. Let's create very unbalanced classes just for the sake of this example! Generate very unbalanced classes by [bootstrapping](http://stattrek.com/statistics/dictionary.aspx?definition=sampling_with_replacement) (a.k.a. random sampling with replacement) the majority class.\n",
    "\n",
    "1. The majority class are those individuals with CKD.\n",
    "2. Generate a random sample of size 200,000 of individuals who have CKD **with replacement**. (Consider setting a random seed for this part!)\n",
    "3. Create a new dataframe with the original data plus this random sample of data.\n",
    "4. Now we should have a dataset with around 200,000 observations, of which only about 0.00075% are non-CKD individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "unbalanced_data = results.sample(n=200000,replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "unbalanced_data['class']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>bu</th>\n",
       "      <th>sc</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wbcc</th>\n",
       "      <th>rbcc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>76.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>8406.122449</td>\n",
       "      <td>4.707435</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>243</td>\n",
       "      <td>62.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>11000.000000</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>383</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>64.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.072454</td>\n",
       "      <td>...</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>8406.122449</td>\n",
       "      <td>4.707435</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>163.0</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>6900.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>41.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>165.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>38.884498</td>\n",
       "      <td>8406.122449</td>\n",
       "      <td>4.707435</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>56.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>309.0</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5400.000000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>70.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>5800.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>34.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>148.036517</td>\n",
       "      <td>219.0</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>38.884498</td>\n",
       "      <td>8406.122449</td>\n",
       "      <td>4.707435</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>353</td>\n",
       "      <td>39.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>5800.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bp  sg  al  su  pcc  ba         bgr     bu         sc  ...  \\\n",
       "151  76.0   90.0   0   0   0    1   1  172.000000   46.0   1.700000  ...   \n",
       "243  62.0   90.0   0   0   0    1   1  169.000000   48.0   2.400000  ...   \n",
       "383  80.0   80.0   0   1   1    1   1  119.000000   46.0   0.700000  ...   \n",
       "216  64.0   70.0   0   1   1    1   1  107.000000   15.0   3.072454  ...   \n",
       "22   48.0   80.0   0   0   1    1   1   95.000000  163.0   7.700000  ...   \n",
       "..    ...    ...  ..  ..  ..  ...  ..         ...    ...        ...  ...   \n",
       "143  41.0   80.0   0   0   0    1   1  210.000000  165.0  18.000000  ...   \n",
       "249  56.0   90.0   0   0   0    0   1  176.000000  309.0  13.300000  ...   \n",
       "87   70.0  100.0   1   0   1    0   1  169.000000   47.0   2.900000  ...   \n",
       "122  34.0   70.0   0   0   0    1   1  148.036517  219.0  12.200000  ...   \n",
       "353  39.0   60.0   0   1   1    1   1   86.000000   37.0   0.600000  ...   \n",
       "\n",
       "           pcv          wbcc      rbcc  htn  dm  cad  appet  pe  ane  class  \n",
       "151  30.000000   8406.122449  4.707435    0   0    1      1   1    0      1  \n",
       "243  47.000000  11000.000000  6.100000    0   1    1      1   1    1      1  \n",
       "383  49.000000   5100.000000  5.000000    1   1    1      1   1    1      1  \n",
       "216  38.000000   8406.122449  4.707435    1   1    1      1   1    1      1  \n",
       "22   32.000000   6900.000000  3.400000    0   1    1      1   1    0      1  \n",
       "..         ...           ...       ...  ...  ..  ...    ...  ..  ...    ...  \n",
       "143  38.884498   8406.122449  4.707435    1   0    1      1   1    1      1  \n",
       "249   9.000000   5400.000000  2.100000    0   0    1      0   0    0      1  \n",
       "87   32.000000   5800.000000  5.000000    0   0    1      0   1    1      1  \n",
       "122  38.884498   8406.122449  4.707435    0   1    1      1   1    0      1  \n",
       "353  51.000000   5800.000000  4.500000    1   1    1      1   1    1      1  \n",
       "\n",
       "[200000 rows x 23 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unbalanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = [results,unbalanced_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. Build a logistic regression model on the unbalanced class data and evaluate its performance using whatever method(s) you see fit. How would you describe the impact of unbalanced classes on logistic regression as a classifier?\n",
    "> Be sure to look at how well it performs on non-CKD data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df[['hemo','al','pcv','dm','bgr','bu']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = new_df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Willy\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>class</td>      <th>  R-squared:         </th>  <td>   0.001</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.001</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   28.90</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 28 Nov 2019</td> <th>  Prob (F-statistic):</th>  <td>8.77e-35</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:12:45</td>     <th>  Log-Likelihood:    </th> <td>4.4176e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>200393</td>      <th>  AIC:               </th> <td>-8.835e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>200386</td>      <th>  BIC:               </th> <td>-8.834e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    1.0019</td> <td>    0.000</td> <td> 2145.294</td> <td> 0.000</td> <td>    1.001</td> <td>    1.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hemo</th>  <td>   -0.0001</td> <td> 4.55e-05</td> <td>   -2.375</td> <td> 0.018</td> <td>   -0.000</td> <td>-1.89e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>al</th>    <td>   -0.0007</td> <td>    0.000</td> <td>   -4.454</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pcv</th>   <td>-2.019e-05</td> <td> 1.44e-05</td> <td>   -1.405</td> <td> 0.160</td> <td>-4.84e-05</td> <td> 7.98e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dm</th>    <td>   -0.0003</td> <td>    0.000</td> <td>   -1.768</td> <td> 0.077</td> <td>   -0.001</td> <td> 3.09e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bgr</th>   <td> 1.076e-06</td> <td> 9.25e-07</td> <td>    1.163</td> <td> 0.245</td> <td>-7.37e-07</td> <td> 2.89e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bu</th>    <td>-2.187e-06</td> <td> 1.47e-06</td> <td>   -1.485</td> <td> 0.138</td> <td>-5.07e-06</td> <td> 6.99e-07</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>562831.633</td> <th>  Durbin-Watson:     </th>    <td>   0.016</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>16270449454.360</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td>-37.346</td>  <th>  Prob(JB):          </th>    <td>    0.00</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>1396.932</td>  <th>  Cond. No.          </th>    <td>1.41e+03</td>    \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.41e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  class   R-squared:                       0.001\n",
       "Model:                            OLS   Adj. R-squared:                  0.001\n",
       "Method:                 Least Squares   F-statistic:                     28.90\n",
       "Date:                Thu, 28 Nov 2019   Prob (F-statistic):           8.77e-35\n",
       "Time:                        14:12:45   Log-Likelihood:             4.4176e+05\n",
       "No. Observations:              200393   AIC:                        -8.835e+05\n",
       "Df Residuals:                  200386   BIC:                        -8.834e+05\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          1.0019      0.000   2145.294      0.000       1.001       1.003\n",
       "hemo          -0.0001   4.55e-05     -2.375      0.018      -0.000   -1.89e-05\n",
       "al            -0.0007      0.000     -4.454      0.000      -0.001      -0.000\n",
       "pcv        -2.019e-05   1.44e-05     -1.405      0.160   -4.84e-05    7.98e-06\n",
       "dm            -0.0003      0.000     -1.768      0.077      -0.001    3.09e-05\n",
       "bgr         1.076e-06   9.25e-07      1.163      0.245   -7.37e-07    2.89e-06\n",
       "bu         -2.187e-06   1.47e-06     -1.485      0.138   -5.07e-06    6.99e-07\n",
       "==============================================================================\n",
       "Omnibus:                   562831.633   Durbin-Watson:                   0.016\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):      16270449454.360\n",
       "Skew:                         -37.346   Prob(JB):                         0.00\n",
       "Kurtosis:                    1396.932   Cond. No.                     1.41e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.41e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y,X)\n",
    "ols = model.fit()\n",
    "ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Willy\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = logr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9993450353680902"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9990518725517104"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00026091, 0.27737854, 0.99889653, 0.63964415, 1.02047354,\n",
       "        1.0122359 ]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(logr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix2 = confusion_matrix(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,    38],\n",
       "       [    0, 40041]], dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6: Answer the problem.\n",
    "\n",
    "At this step, you would generally answer the problem! In this situation, you would likely present your model to doctors or administrators at the hospital and show how your model results in reduced false positives/false negatives. Next steps would be to find a way to roll this model and its conclusions out across the hospital so that the outcomes of patients with CKD (and without CKD!) can be improved!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
